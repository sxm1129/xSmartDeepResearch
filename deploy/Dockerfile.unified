# xSmartDeepResearch Unified Dockerfile
# Combines Python Backend + React Frontend in a single image

# ============================================
# Stage 1: Build Frontend
# ============================================
FROM node:18-alpine AS frontend-builder

WORKDIR /app/web

# Copy VERSION file for vite.config.ts to read
COPY VERSION /app/VERSION

# Copy package files first for better caching
COPY web/package*.json ./

# Install dependencies
RUN npm config set registry https://registry.npmmirror.com
RUN npm install --legacy-peer-deps

# Copy frontend source and build
COPY web/ ./
RUN npm run build

# ============================================
# Stage 2: Production Image
# ============================================
FROM python:3.10-slim

ARG APP_VERSION=1.0.13
LABEL maintainer="xSmartDeepResearch"
LABEL version="${APP_VERSION}"

# Set environment variables
ENV PYTHONPATH=/app
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1

WORKDIR /app

# Install system dependencies (nginx, supervisor, and build tools)
# Use Aliyun mirror for Debian
RUN sed -i 's/deb.debian.org/mirrors.aliyun.com/g' /etc/apt/sources.list.d/debian.sources && \
    sed -i 's/security.debian.org/mirrors.aliyun.com/g' /etc/apt/sources.list.d/debian.sources

RUN apt-get update && \
    for i in 1 2 3; do \
    apt-get install -y --no-install-recommends --fix-missing \
    nginx \
    supervisor \
    build-essential \
    curl \
    git \
    default-libmysqlclient-dev \
    pkg-config \
    && break || sleep 5; \
    done && \
    rm -rf /var/lib/apt/lists/* && \
    apt-get clean

# Copy and install Python dependencies
# Step 1: Install CPU-only PyTorch first (avoids downloading ~3.5GB NVIDIA CUDA libs)
RUN pip install --no-cache-dir --default-timeout=1000 \
    -i https://mirrors.aliyun.com/pypi/simple/ \
    --trusted-host mirrors.aliyun.com \
    torch --extra-index-url https://download.pytorch.org/whl/cpu

# Step 2: Install remaining dependencies (will reuse the CPU torch already installed)
COPY requirements.txt .
RUN pip install --no-cache-dir --default-timeout=1000 \
    -i https://mirrors.aliyun.com/pypi/simple/ \
    --trusted-host mirrors.aliyun.com \
    -r requirements.txt

# Step 3: Pre-download sentence-transformers model from ModelScope (China mirror)
ENV HF_HOME=/app/.hf_cache
ENV SENTENCE_TRANSFORMERS_HOME=/app/models
RUN pip install --no-cache-dir -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com modelscope && \
    python -c "from modelscope import snapshot_download; snapshot_download('sentence-transformers/all-MiniLM-L6-v2', cache_dir='/app/models')" && \
    pip uninstall -y modelscope

# Copy backend source code
COPY src/ ./src/
COPY config/ ./config/
COPY scripts/ ./scripts/
COPY VERSION ./VERSION

# Copy built frontend from Stage 1
COPY --from=frontend-builder /app/web/dist /var/www/html

# Copy Nginx configuration
COPY deploy/nginx.conf /etc/nginx/sites-available/default

# Copy Supervisor configuration
COPY deploy/supervisord.conf /etc/supervisor/conf.d/supervisord.conf

# Create necessary directories
RUN mkdir -p /app/data /app/logs /var/log/supervisor

# Expose ports (80 for frontend via Nginx, 8000 for direct API access)
EXPOSE 80 8000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=10s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Start Supervisor (manages nginx + uvicorn)
CMD ["/usr/bin/supervisord", "-c", "/etc/supervisor/conf.d/supervisord.conf"]
