"""xSmartDeepResearch ReAct Agent æ ¸å¿ƒå®ç°"""

import json
import time
import re
from typing import Dict, Any, List, Optional, Union
from dataclasses import dataclass, field
from datetime import datetime

from openai import OpenAI

from config import settings, build_system_prompt, FORCE_SUMMARIZE_PROMPT
from src.tools import BaseTool, ToolRegistry
from src.agent.intent_classifier import IntentClassifier
from src.utils.logger import logger
from src.utils.session_manager import SessionManager


@dataclass
class ResearchResult:
    """ç ”ç©¶ç»“æœ"""
    question: str
    answer: str
    prediction: str
    messages: List[Dict[str, str]]
    termination: str
    execution_time: float = 0.0
    iterations: int = 0
    
    def dict(self) -> Dict[str, Any]:
        return {
            "question": self.question,
            "answer": self.answer,
            "prediction": self.prediction,
            "messages": self.messages,
            "termination": self.termination,
            "execution_time": self.execution_time,
            "iterations": self.iterations
        }


class xSmartReactAgent:
    """xSmartDeepResearch ReAct Agent
    
    åŸºäº ReAct (Reasoning + Acting) æ¡†æ¶çš„æ™ºèƒ½ç ”ç©¶ä»£ç†ï¼Œ
    æ”¯æŒå¤šè½®æ€è€ƒ-è¡ŒåŠ¨-è§‚å¯Ÿå¾ªç¯ï¼Œèƒ½å¤Ÿè‡ªä¸»è¿›è¡Œæ·±åº¦ä¿¡æ¯æ£€ç´¢å’Œæ¨ç†ã€‚
    """
    
    # ç‰¹æ®Šæ ‡è®°
    TOOL_CALL_START = "<tool_call>"
    TOOL_CALL_END = "</tool_call>"
    TOOL_RESPONSE_START = "<tool_response>"
    TOOL_RESPONSE_END = "</tool_response>"
    THINK_START = "<think>"
    THINK_END = "</think>"
    ANSWER_START = "<answer>"
    ANSWER_END = "</answer>"
    CODE_START = "<code>"
    CODE_END = "</code>"
    
    def __init__(
        self,
        client: OpenAI = None,
        model: str = None,
        tools: List[BaseTool] = None,
        max_iterations: int = None,
        max_tokens: int = None,
        temperature: float = None,
        top_p: float = None,
        presence_penalty: float = None,
        timeout_minutes: int = 150,
        classifier_model: str = "gpt-4o-mini"
    ):
        """åˆå§‹åŒ– ReAct Agent
        
        Args:
            client: OpenAI å…¼å®¹çš„å®¢æˆ·ç«¯
            model: æ¨¡å‹åç§°
            tools: å·¥å…·åˆ—è¡¨
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
            max_tokens: æœ€å¤§ä¸Šä¸‹æ–‡ token æ•°
            temperature: é‡‡æ ·æ¸©åº¦
            top_p: nucleus é‡‡æ ·å‚æ•°
            presence_penalty: å­˜åœ¨æƒ©ç½š
            timeout_minutes: è¶…æ—¶åˆ†é’Ÿæ•°
        """
        # å®¢æˆ·ç«¯é…ç½®
        self.client = client or OpenAI(
            api_key=settings.api_key,
            base_url=settings.api_base,
            timeout=600.0
        )
        self.model = model or settings.model_name
        
        # Agent é…ç½®
        self.max_iterations = max_iterations or settings.max_llm_call_per_run
        self.max_tokens = max_tokens or settings.max_context_tokens
        self.temperature = temperature or settings.temperature
        self.top_p = top_p or settings.top_p
        self.presence_penalty = presence_penalty or settings.presence_penalty
        self.timeout_minutes = timeout_minutes
        
        # æ„å›¾åˆ†ç±»å™¨
        self.classifier = IntentClassifier(self.client, model=classifier_model)
        
        # ä¼šè¯ç®¡ç†å™¨
        self.session_manager = SessionManager()
        self.current_session_id = None
        self.current_project_id = None # ç”¨äºç»‘å®šå½“å‰ Project
        
        # å·¥å…·é…ç½®
        self.tools = {tool.name: tool for tool in (tools or [])}
        
        # Token è®¡æ•°å™¨ (æ‡’åŠ è½½)
        self._tokenizer = None
    
    @property
    def tokenizer(self):
        """æ‡’åŠ è½½ tokenizer"""
        if self._tokenizer is None:
            try:
                import tiktoken
                self._tokenizer = tiktoken.get_encoding("cl100k_base")
            except ImportError:
                self._tokenizer = None
        return self._tokenizer
    
    def register_tool(self, tool: BaseTool) -> None:
        """æ³¨å†Œå·¥å…·
        
        Args:
            tool: å·¥å…·å®ä¾‹
        """
        self.tools[tool.name] = tool
    
    def run(self, question: str, ground_truth: str = "") -> ResearchResult:
        """æ‰§è¡Œç ”ç©¶ä»»åŠ¡ (åŒæ­¥ç‰ˆæœ¬)"""
        start_time = time.time()
        
        # ä½¿ç”¨ç”Ÿæˆå™¨è¿è¡Œå¹¶ç´¯ç§¯ç»“æœ
        messages = []
        prediction = ""
        iterations = 0
        termination = "unknown"
        
        for event in self.stream_run(question):
            event_type = event.get("type")
            
            if event_type == "final_answer":
                prediction = event.get("content", "")
                messages = event.get("messages", [])
                iterations = event.get("iterations", 0)
                termination = event.get("termination", "answer")
            elif event_type == "error":
                prediction = event.get("content", "Error occurred")
                termination = "error"
            elif event_type == "timeout":
                prediction = "Timeout"
                termination = "timeout"
        
        return ResearchResult(
            question=question,
            answer=ground_truth,
            prediction=prediction,
            messages=messages,
            termination=termination,
            execution_time=time.time() - start_time,
            iterations=iterations
        )

    def stream_run(self, question: str):
        """æ‰§è¡Œç ”ç©¶ä»»åŠ¡ (æµå¼ç”Ÿæˆå™¨ç‰ˆæœ¬)
        
        Yields:
            Dict[str, Any]: åŒ…å« type å’Œ content çš„äº‹ä»¶å­—å…¸
        """
        start_time = time.time()
        
        # ğŸŸ¢ æ­¥éª¤ 1: æ„å›¾è¯†åˆ« (åŠ¨æ€äººè®¾æ³¨å…¥)
        yield {"type": "status", "content": "ğŸ” Identifying research intent..."}
        # PERSIST: status
        if self.current_session_id:
             self.session_manager.add_message(self.current_session_id, "status", "ğŸ” Identifying research intent...")

        intent = self.classifier.classify(question)
        category = intent.get("category", "general")
        reason = intent.get("reason", "")
        status_msg = f"ğŸ¯ Intent: **{category.upper()}** ({reason})"
        yield {"type": "status", "content": status_msg}
        # PERSIST: status (Create session happens next, so we can't persist this one yet unless we move session creation up. 
        # Actually session creation is the next step. So we should persist this AFTER session creation.)

        # ğŸ”µ æ­¥éª¤ 2: åˆ›å»ºä¼šè¯æŒä¹…åŒ–
        self.current_session_id = self.session_manager.create_session(
            title=question[:50],  # ç®€å•å–å‰50å­—ç¬¦ä½œä¸ºæ ‡é¢˜
            intent_category=category,
            project_id=self.current_project_id
        )
        # è®°å½•ç”¨æˆ·é—®é¢˜
        self.session_manager.add_message(self.current_session_id, "user", question)
        # PERSIST: Delayed status messages
        self.session_manager.add_message(self.current_session_id, "status", status_msg)

        # æ„å»ºåˆå§‹æ¶ˆæ¯
        tool_definitions = [tool.get_function_definition() for tool in self.tools.values()]
        system_prompt = build_system_prompt(tool_definitions, category=category)
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": question}
        ]
        
        iterations = 0
        
        while iterations < self.max_iterations:
            elapsed_minutes = (time.time() - start_time) / 60
            if elapsed_minutes > self.timeout_minutes:
                yield {"type": "timeout", "content": "Research timeout"}
                return

            iterations += 1
            yield {"type": "status", "content": f"Iteration {iterations}...", "iteration": iterations}
            self.session_manager.add_message(self.current_session_id, "status", f"Iteration {iterations}...")
            
            # è°ƒç”¨ LLM
            response = self._call_llm(messages)
            
            if self.TOOL_RESPONSE_START in response:
                pos = response.find(self.TOOL_RESPONSE_START)
                response = response[:pos]
            
            messages.append({"role": "assistant", "content": response.strip()})
            
            # æå–æ€è€ƒè¿‡ç¨‹
            if self.THINK_START in response:
                think_match = re.search(f"{re.escape(self.THINK_START)}(.*?){re.escape(self.THINK_END)}", response, re.DOTALL)
                if think_match:
                    think_content = think_match.group(1).strip()
                else:
                    # å®¹é”™ï¼šå¤„ç†æœªé—­åˆæ ‡ç­¾
                    think_content = response.split(self.THINK_START)[-1].strip()
                    # å¦‚æœåé¢æœ‰å·¥å…·è°ƒç”¨æˆ–ç­”æ¡ˆæ ‡ç­¾ï¼Œæˆªæ–­å®ƒä»¬
                    for tag in [self.TOOL_CALL_START, self.ANSWER_START]:
                        if tag in think_content:
                            think_content = think_content.split(tag)[0].strip()
                
                if think_content:
                    yield {"type": "think", "content": think_content}
                    # è®°å½•æ€è€ƒæ­¥éª¤
                    self.session_manager.add_message(self.current_session_id, "thought", think_content)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æœ€ç»ˆç­”æ¡ˆ
            if self._has_answer(response):
                prediction = self._extract_answer(response)
                
                # è®°å½•æœ€ç»ˆç­”æ¡ˆ
                self.session_manager.add_message(self.current_session_id, "answer", prediction)
                
                yield {"type": "answer", "content": prediction}
                yield {
                    "type": "final_answer", 
                    "content": prediction, 
                    "messages": messages, 
                    "iterations": iterations,
                    "termination": "answer"
                }
                return
            
            # æ£€æŸ¥å¹¶æ‰§è¡Œå·¥å…·è°ƒç”¨
            if self._has_tool_call(response):
                # æå–å·¥å…·åä¸å‚æ•°ç”¨äºçŠ¶æ€æç¤º
                tool_match = re.search(r'<tool_call>(.*?)</tool_call>', response, re.DOTALL)
                tool_name = "unknown"
                tool_args = {}
                if tool_match:
                    try:
                        import json5
                        tc_json = json5.loads(tool_match.group(1).strip())
                        tool_name = tc_json.get("name", "tool")
                        tool_args = tc_json.get("arguments", {})
                    except: pass
                
                yield {
                    "type": "tool_start", 
                    "content": f"Calling tool: {tool_name}", 
                    "tool": tool_name,
                    "arguments": tool_args,
                    "iteration": iterations
                }
                
                logger.info(f"ğŸ”§ Executing tool: {tool_name} with args: {tool_args}")
                tool_result = self._execute_tool_call(response)
                
                # è®°å½•å·¥å…·è°ƒç”¨çš„è¯¦ç»†ä¿¡æ¯
                self.session_manager.add_message(
                    self.current_session_id, 
                    "tool", 
                    f"Call: {tool_name}\nArgs: {json.dumps(tool_args, ensure_ascii=False)}\nResult: {tool_result}",
                    metadata={"tool_name": tool_name, "args": tool_args}
                )

                # PERSIST: tool_response
                self.session_manager.add_message(
                    self.current_session_id,
                    "tool_response",
                    tool_result,
                    metadata={"tool_name": tool_name}
                )

                yield {
                    "type": "tool_response", 
                    "content": tool_result, 
                    "tool": tool_name,
                    "iteration": iterations
                }
                
                messages.append({
                    "role": "user",
                    "content": f"{self.TOOL_RESPONSE_START}\n{tool_result}\n{self.TOOL_RESPONSE_END}"
                })
            
            # æ£€æŸ¥ token é™åˆ¶
            token_count = self._count_tokens(messages)
            if token_count > self.max_tokens:
                # å¦‚æœè¿˜æœ‰å¾ˆå¤šæ­¥å¯ä»¥èµ°ï¼Œå°è¯•å‰ªæè€Œä¸æ˜¯ç«‹å³æ€»ç»“
                if iterations < self.max_iterations - 3:
                    logger.info(f"Token count {token_count} exceeds {self.max_tokens}. Pruning context.")
                    messages = self._prune_messages(messages)
                    yield {"type": "status", "content": "Context pruned to save tokens."}
                    self.session_manager.add_message(self.current_session_id, "status", "Context pruned to save tokens.")
                else:
                    yield {"type": "status", "content": "Token limit reached, forcing final summary..."}
                    self.session_manager.add_message(self.current_session_id, "status", "Token limit reached, forcing final summary...")
                    res = self._force_summarize(messages, question, "", start_time, iterations)
                    yield {"type": "answer", "content": res.prediction}
                    yield {
                        "type": "final_answer", 
                        "content": res.prediction, 
                        "messages": messages, 
                        "iterations": iterations,
                        "termination": res.termination
                    }
                    return

        yield {"type": "error", "content": "Max iterations exceeded"}
        yield {
            "type": "final_answer", 
            "content": "Max iterations reached without final answer", 
            "messages": messages, 
            "iterations": iterations,
            "termination": "max_iterations_exceeded"
        }

    
    def _call_llm(self, messages: List[Dict], max_retries: int = 10) -> str:
        """è°ƒç”¨ LLM
        
        Args:
            messages: æ¶ˆæ¯å†å²
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            
        Returns:
            LLM å“åº”å†…å®¹
        """
        base_sleep_time = 1
        
        for attempt in range(max_retries):
            try:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    stop=[f"\n{self.TOOL_RESPONSE_START}", self.TOOL_RESPONSE_START],
                    temperature=self.temperature,
                    top_p=self.top_p,
                    presence_penalty=self.presence_penalty,
                    max_tokens=10000
                )
                
                content = response.choices[0].message.content
                if content and content.strip():
                    return content.strip()
                    
            except Exception as e:
                logger.error(f"[LLM] Attempt {attempt + 1} failed: {e}")
            
            if attempt < max_retries - 1:
                sleep_time = min(base_sleep_time * (2 ** attempt), 30)
                time.sleep(sleep_time)
        
        return "LLM call failed after all retries"
    
    def _has_answer(self, content: str) -> bool:
        """æ£€æŸ¥å†…å®¹ä¸­æ˜¯å¦åŒ…å«æœ€ç»ˆç­”æ¡ˆ"""
        return self.ANSWER_START in content # å®¹é”™ï¼šåªè¦æœ‰å¼€å§‹æ ‡ç­¾å°±è®¤ä¸ºæœ‰ç­”æ¡ˆ
    
    def _extract_answer(self, content: str) -> str:
        """ä»å“åº”å†…å®¹ä¸­æå–æœ€ç»ˆç­”æ¡ˆ"""
        # å°è¯•åŒ¹é…é—­åˆæ ‡ç­¾
        match = re.search(f"{re.escape(self.ANSWER_START)}(.*?){re.escape(self.ANSWER_END)}", content, re.DOTALL)
        if match:
            return match.group(1).strip()
        
        # å®¹é”™ï¼šå°è¯•åŒ¹é…æœªé—­åˆçš„å¼€å§‹æ ‡ç­¾
        if self.ANSWER_START in content:
            return content.split(self.ANSWER_START)[-1].strip()
            
        return content.strip()
    
    def _has_tool_call(self, content: str) -> bool:
        """æ£€æŸ¥å†…å®¹ä¸­æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨"""
        return bool(re.search(r'<tool_call>.*?</tool_call>', content, re.DOTALL)) or \
               bool(re.search(r'<tool_call>.*', content, re.DOTALL)) # å®¹é”™ï¼šå…è®¸æœªé—­åˆæ ‡ç­¾
    
    def _execute_tool_call(self, content: str) -> str:
        """è§£æå¹¶æ‰§è¡Œå·¥å…·è°ƒç”¨"""
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–å·¥å…·è°ƒç”¨å†…å®¹ï¼Œå¤„ç†å¤šç§è¾¹ç•Œæƒ…å†µ
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–å·¥å…·è°ƒç”¨å†…å®¹ï¼Œå¤„ç†å¤šç§è¾¹ç•Œæƒ…å†µ
        patterns = [
            r'<tool_call>\s*(.*?)\s*</tool_call>',
            r'<tool_call>(.*?)(?:</tool_call>|$)', # éè´ªå©ªåŒ¹é…ï¼Œé˜²æ­¢åæ‰åé¢çš„å†…å®¹ï¼Œå¹¶å…è®¸çœç•¥é—­åˆæ ‡ç­¾
        ]
        
        tool_call_str = ""
        for pattern in patterns:
            match = re.search(pattern, content, re.DOTALL)
            if match:
                tool_call_str = match.group(1).strip()
                if tool_call_str: break
        
        if not tool_call_str:
            return "[Error] No valid <tool_call> content found."

        # æ¸…ç†å¸¸è§çš„å¹»è§‰æ ‡ç­¾
        tool_call_str = tool_call_str.replace("</arg_value>", "").replace("<arg_value>", "")
        tool_call_str = tool_call_str.replace("</tool_code>", "").replace("<tool_code>", "")

        try:
            # å°è¯•è§£æ JSON
            import json5
            try:
                tool_call_json = json5.loads(tool_call_str)
            except:
                # ç®€å•ä¿®å¤ï¼šå°è¯•å¹³è¡¡æ‹¬å·å’Œå¤„ç†å¼•å·
                # è¿™é‡Œåªæ˜¯æœ€ç®€å•çš„å¯å‘å¼ä¿®å¤
                fixed_str = tool_call_str.strip()
                if not fixed_str.endswith('}'): fixed_str += '}'
                tool_call_json = json5.loads(fixed_str)
            
            tool_name = tool_call_json.get("name")
            tool_args = tool_call_json.get("arguments", tool_call_json.get("parameters", {}))
            
            # ç‰¹æ®Šå¤„ç† PythonInterpreter å¿«æ·è°ƒç”¨
            if tool_name == "PythonInterpreter" and "code" not in tool_args and self.CODE_START in content:
                code_start = content.find(self.CODE_START) + len(self.CODE_START)
                code_end = content.find(self.CODE_END)
                if code_end != -1:
                    tool_args = content[code_start:code_end].strip()
            
            if tool_name in self.tools:
                print(f"ğŸ”§ Tool Call: {tool_name}")
                return self.tools[tool_name].call(tool_args)
            else:
                return f"[Error] Tool '{tool_name}' not found. Available: {list(self.tools.keys())}"
                
        except Exception as e:
            return f"[Error] Failed to parse tool call JSON: {tool_call_str[:200]}... Error: {str(e)}"
    
    def _count_tokens(self, messages: List[Dict]) -> int:
        """è®¡ç®—æ¶ˆæ¯çš„ token æ•°
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            token æ•°é‡
        """
        if self.tokenizer is None:
            # ç²—ç•¥ä¼°è®¡ï¼š4ä¸ªå­—ç¬¦çº¦ç­‰äº1ä¸ªtoken
            total_chars = sum(len(m.get("content", "")) for m in messages)
            return total_chars // 4
        
        full_text = "\n".join(m.get("content", "") for m in messages)
        tokens = self.tokenizer.encode(full_text)
        return len(tokens)
    
    def _force_summarize(
        self, 
        messages: List[Dict],
        question: str,
        ground_truth: str,
        start_time: float,
        iterations: int
    ) -> ResearchResult:
        """å¼ºåˆ¶æ€»ç»“ï¼ˆtoken è¶…é™æ—¶ä½¿ç”¨ï¼‰
        
        Args:
            messages: å½“å‰æ¶ˆæ¯å†å²
            question: åŸå§‹é—®é¢˜
            ground_truth: å‚è€ƒç­”æ¡ˆ
            start_time: å¼€å§‹æ—¶é—´
            iterations: å·²è¿­ä»£æ¬¡æ•°
            
        Returns:
            ç ”ç©¶ç»“æœ
        """
        # æ·»åŠ å¼ºåˆ¶æ€»ç»“æç¤º
        messages[-1]["content"] = FORCE_SUMMARIZE_PROMPT
        
        # å†æ¬¡è°ƒç”¨ LLM
        response = self._call_llm(messages)
        messages.append({"role": "assistant", "content": response.strip()})
        
        if self._has_answer(response):
            prediction = self._extract_answer(response)
            termination = "token_limit_forced_answer"
        else:
            prediction = response
            termination = "token_limit_format_error"
        
        return ResearchResult(
            question=question,
            answer=ground_truth,
            prediction=prediction,
            messages=messages,
            termination=termination,
            execution_time=time.time() - start_time,
            iterations=iterations
        )

    def _prune_messages(self, messages: List[Dict]) -> List[Dict]:
        """å‰ªææ¶ˆæ¯å†å²ï¼Œä¿ç•™æ ¸å¿ƒä¸Šä¸‹æ–‡"""
        if len(messages) <= 8:
            return messages
            
        # 1. ä¿ç•™ System Prompt å’ŒåŸå§‹ User Question
        # æ³¨æ„ï¼šæœ‰æ—¶å€™ç¬¬ä¸€ä¸ªæ¶ˆæ¯ä¸æ˜¯ systemï¼Œæˆ–è€…ç¬¬äºŒä¸ªä¸æ˜¯ userï¼Œä½†è¿™é‡Œåšä¸€èˆ¬æ€§å‡è®¾
        kept_head = messages[:2]
        
        # 2. ä¿ç•™æœ€è¿‘çš„ 3 æ¬¡äº¤äº’ (Assistant + User å…± 6 æ¡æ¶ˆæ¯)
        kept_tail = messages[-6:]
        
        # 3. æ„é€ å‰ªææç¤º
        pruned_notice = {
            "role": "system", 
            "content": f"[System Note: Earlier conversation turns have been removed to save tokens. Current token usage: {self._count_tokens(kept_head + kept_tail)}]"
        }
        
        return kept_head + [pruned_notice] + kept_tail
